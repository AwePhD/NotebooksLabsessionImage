{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKBr5mgKRV1g",
        "outputId": "cdb40580-385c-426c-e31d-770f44798914",
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/AwePhD/NotebooksLabsessionImage.git\n",
            "  Cloning https://github.com/AwePhD/NotebooksLabsessionImage.git to /tmp/pip-req-build-3vdf1de3\n",
            "  Running command git clone -q https://github.com/AwePhD/NotebooksLabsessionImage.git /tmp/pip-req-build-3vdf1de3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from NLI==1.0.0) (1.1.5)\n",
            "Requirement already satisfied: scikit-image==0.18.3 in /usr/local/lib/python3.7/dist-packages (from NLI==1.0.0) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->NLI==1.0.0) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->NLI==1.0.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->NLI==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.3->NLI==1.0.0) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.3->NLI==1.0.0) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.3->NLI==1.0.0) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.3->NLI==1.0.0) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.3->NLI==1.0.0) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.3->NLI==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.3->NLI==1.0.0) (2021.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3->NLI==1.0.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3->NLI==1.0.0) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.3->NLI==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.5->NLI==1.0.0) (1.15.0)\n",
            "Building wheels for collected packages: NLI\n",
            "  Building wheel for NLI (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NLI: filename=NLI-1.0.0-py3-none-any.whl size=2406 sha256=1560bca79741ab76575f29d7909879ca0bdb2ee81d8ce93d940f944b7820964b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c4y459bw/wheels/17/4a/a4/4f920391e876c3c2632ecc7851748e1c11539349fe2eefd2c4\n",
            "Successfully built NLI\n",
            "Installing collected packages: NLI\n",
            "Successfully installed NLI-1.0.0\n"
          ]
        }
      ],
      "source": [
        "# Install the environnement\n",
        "%pip install git+https://github.com/AwePhD/NotebooksLabsessionImage.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSv2bpyERV1k",
        "outputId": "67389fa1-d5d9-4547-d296-cd8db57234f5",
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   156  100   156    0     0    445      0 --:--:-- --:--:-- --:--:--   444\n",
            "100 2484k  100 2484k    0     0  4155k      0 --:--:-- --:--:-- --:--:-- 4155k\n"
          ]
        }
      ],
      "source": [
        "# Import dataset \n",
        "# Can be found at https://www.kaggle.com/vishalsubbiah/pokemon-images-and-types\n",
        "!rm -rf ./*\n",
        "!curl -LO https://github.com/AwePhD/NotebooksLabsessionImage/raw/main/pokemon_dataset.zip\n",
        "!unzip -qq pokemon_dataset.zip\n",
        "!rm pokemon_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jjJJ1JydRV1l",
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "# Standard imports\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "from typing import List, Dict\n",
        "\n",
        "# Third party imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "from skimage import data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_zBB9wqWr0a",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Use of numpy witn ndarray for Image processing\n",
        "\n",
        "Numpy array - `ndarray` - is the most used data structure in Numpy package (maybe overall Python packages). This array has a *ton of features* which are used in data processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "Basically, you can use the numpy array to store variables with a fixed `dtype`. More on data type in Numpy [here](https://jakevdp.github.io/PythonDataScienceHandbook/02.01-understanding-data-types.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3., 2.])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([3, 2], dtype=np.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 2], dtype=int16)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([3, 2], dtype=np.int16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([3, 2], dtype=np.int16)  == np.array([3, 2], dtype=np.float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Getting information about `ndarray` objects\n",
        "\n",
        "There are several information that you can get on a ndarray, a more details walkthrough is available [here](https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html).\n",
        "\n",
        "We will illustrate some features of the ndarray on the object `data`. It has 3 dimensions like RGB images: first two dimensions can be interpreted as width and height and third one is the RGB value of each pixel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "data = np.random.random((500, 250, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data dimension: 3\n",
            "data shape: (500, 250, 3)\n",
            "data size: 375000\n",
            "data dtype: float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f\"data dimension: {data.ndim}\\n\"\n",
        "    f\"data shape: {data.shape}\\n\"\n",
        "    f\"data size: {data.size}\\n\"\n",
        "    f\"data dtype: {data.dtype}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "As we will see later in this notebook and during lab session, it's extremely important to keep in mind the data type contained in `ndarray` and the shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### \"Smart artihmetic\" operation on `ndarray`\n",
        "\n",
        "The _smart_ arithmetic is known as **broadcasting**. There [is a section](https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html) of the Python Data Handbook which is about this feature. Mainly, we can use `ndarray` easily and handily. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "Let's add one to our `data` variable. Due to the broadcasting, Python handles an addition between an `int` and a `ndarray` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvX438Jmfw1N",
        "outputId": "2b202beb-14fa-4de9-f433-e5741a1a2642",
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data[25,30,0]: 0.66\n",
            "data_plus_one[25,30,0]: 1.66\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_plus_one: np.ndarray = data + 1\n",
        "print(\n",
        "    f\"data[25,30,0]: {data[25,30,0]:.2f}\\n\"\n",
        "    f\"data_plus_one[25,30,0]: {data_plus_one[25,30,0]:.2f}\\n\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "More, we can add the following to the code. We can add a 1D vector that will add to every components based on the minimum dimensions. This might be useful for linear algebra computation for example. This example is not useful in itself, this is just to exhibit the power of broadcasting.\n",
        "\n",
        "Plus, this broadcasting enables Python to vectorize the operation, so it's much more performant than a for loop, for instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "np.arange(3): [0 1 2]\n",
            "-----------------------------------\n",
            "data[25,30,0]: 0.66\n",
            "data_plus_vector[25,30,0]: 0.66\n",
            "-----------------------------------\n",
            "data[24,0,0]: 0.93\n",
            "data_plus_vector[24,0,120]: 0.93\n",
            "-----------------------------------\n",
            "data[25,30,1]: 0.28\n",
            "data_plus_vector[25,30,1]: 1.28\n",
            "-----------------------------------\n",
            "data[25,30,122]: 0.70\n",
            "data_plus_vector[25,30,2]: 2.70\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data_plus_vector: np.ndarray = data + np.arange(3)\n",
        "print(\n",
        "    f\"np.arange(3): {np.arange(3)}\\n\"\n",
        "    f\"{'':-^35}\\n\"\n",
        "    f\"data[25,30,0]: {data[25,30,0]:.2f}\\n\"\n",
        "    f\"data_plus_vector[25,30,0]: {data_plus_vector[25,30,0]:.2f}\\n\"\n",
        "    f\"{'':-^35}\\n\"\n",
        "    f\"data[24,0,0]: {data[24,0,0]:.2f}\\n\"\n",
        "    f\"data_plus_vector[24,0,120]: {data_plus_vector[24,0,0]:.2f}\\n\"\n",
        "    f\"{'':-^35}\\n\"\n",
        "    f\"data[25,30,1]: {data[25,30,1]:.2f}\\n\"\n",
        "    f\"data_plus_vector[25,30,1]: {data_plus_vector[25,30,1]:.2f}\\n\"\n",
        "    f\"{'':-^35}\\n\"\n",
        "    f\"data[25,30,122]: {data[25,30,2]:.2f}\\n\"\n",
        "    f\"data_plus_vector[25,30,2]: {data_plus_vector[25,30,2]:.2f}\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Mean processing\n",
        "\n",
        "We can process the mean easily. Here a brief section to illustrate how to do it. For more details how to process other stats, check the [section](https://jakevdp.github.io/PythonDataScienceHandbook/02.04-computation-on-arrays-aggregates.html) of Python Datascience Handbook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "Let's imagine, we are going to take the temperature during 1 day every hours in 50 cities in France. So, each town has 24 points to represent the temperature during the day. I take some random data over an uniform distribution as dummy values for illustration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFoIztJRkj26",
        "outputId": "955500a0-6d6a-4b8a-9369-122689c4b7f2",
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "temperature_in_cities: np.ndarray = np.random.uniform(low=5, high=12, size=(50,24))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "Then, we would like to have the mean temperature over every hours and every towns in our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.460650036106923"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temperature_in_cities.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "Now, we can have the mean temperature for each city. We need to compute the mean on the 24 hours of the day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (50,)\n",
            "mean temperature for city 0: 8.83°C\n"
          ]
        }
      ],
      "source": [
        "mean_temp_in_cities_over_1_day: np.ndarray = temperature_in_cities.mean(1)\n",
        "print(\n",
        "    f\"shape: {mean_temp_in_cities_over_1_day.shape}\\n\"\n",
        "    f\"mean temperature for city 0: {mean_temp_in_cities_over_1_day[0]:.2f}°C\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "Vice versa, we would like to have the mean temperature over the cities for every hours of the day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (24,)\n",
            "Mean temperature at 8AM: 8.03°C\n"
          ]
        }
      ],
      "source": [
        "mean_temp_in_hours_over_all_cities: np.ndarray = temperature_in_cities.mean(0)\n",
        "print(\n",
        "    f\"shape: {mean_temp_in_hours_over_all_cities.shape}\\n\"\n",
        "    f\"Mean temperature at 8AM: {mean_temp_in_hours_over_all_cities[7]:.2f}°C\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "image_processing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d06f5c508cb6d412c5fc39a624b56d5d87ea0c4834e1bf11b5c4d9b980382d19"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
